{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9vUFkL8inXKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "p3vE9yV0nXqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a Feedforward Neural Network\n",
        "''' MLP '''\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, channel, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc_1 = nn.Linear(28*28*1 if channel==1 else 32*32*3, 128)\n",
        "        self.fc_2 = nn.Linear(128, 128)\n",
        "        self.fc_3 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.view(x.size(0), -1)\n",
        "        out = F.relu(self.fc_1(out))\n",
        "        out = F.relu(self.fc_2(out))\n",
        "        out = self.fc_3(out)\n",
        "        return out\n",
        "\n",
        "# Preparing the MNIST dataset\n",
        "dataset_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "mnist_training = datasets.MNIST(root='./data', train=True, download=True, transform=dataset_transform)\n",
        "mnist_testing = datasets.MNIST(root='./data', train=False, download=True, transform=dataset_transform)\n",
        "\n",
        "training_loader = DataLoader(mnist_training, batch_size=64, shuffle=True)\n",
        "testing_loader = DataLoader(mnist_testing, batch_size=64, shuffle=False)\n",
        "\n",
        "# Setting up the neural network\n",
        "ff_network = MLP(input_channels=1, class_count=10)\n",
        "\n",
        "# Loss function, optimizer, and learning rate scheduler\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "sgd_optimizer = optim.SGD(ff_network.parameters(), lr=0.01, momentum=0.9)\n",
        "lr_scheduler = CosineAnnealingLR(sgd_optimizer, T_max=20, eta_min=0.001)\n",
        "\n",
        "# Training procedure\n",
        "def model_training(network, loader, loss_fn, optimizer):\n",
        "    network.train()\n",
        "    for _, (inputs, targets) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        predictions = network(inputs)\n",
        "        loss = loss_fn(predictions, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Testing procedure\n",
        "def model_testing(network, loader):\n",
        "    network.eval()\n",
        "    total_correct = 0\n",
        "    cumulative_flops = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            predictions = network(inputs)\n",
        "            _, preds = predictions.max(1)\n",
        "            total_correct += preds.eq(targets).sum().item()\n",
        "\n",
        "            # FLOPs Calculation\n",
        "            flops = 2 * 128 * network.flatten_size\n",
        "            cumulative_flops += flops\n",
        "\n",
        "    test_accuracy = total_correct / len(loader.dataset)\n",
        "    flops_per_second = cumulative_flops / len(loader.dataset)\n",
        "\n",
        "    return test_accuracy, flops_per_second\n",
        "\n",
        "# Running the training cycles\n",
        "for epoch in range(20):\n",
        "    model_training(ff_network, training_loader, loss_function, sgd_optimizer)\n",
        "    lr_scheduler.step()\n",
        "\n",
        "# Evaluating the network\n",
        "accuracy, flops = model_testing(ff_network, testing_loader)\n",
        "print(\"Accuracy of Model: {:.2f}%\".format(accuracy * 100))\n",
        "print(\"FLOPs per Second: {:.2f}\".format(flops))\n"
      ],
      "metadata": {
        "id": "1mG7t_opnk8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6r309V1nDCH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from utils.utils_gsam import get_dataset, get_network, get_daparam,\\\n",
        "    TensorDataset, epoch, ParamDiffAug\n",
        "import copy\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def main(args):\n",
        "\n",
        "    args.dsa = True if args.dsa == 'True' else False\n",
        "    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    args.dsa_param = ParamDiffAug()\n",
        "\n",
        "    channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader, loader_train_dict, class_map, class_map_inv = get_dataset(args.dataset, args.data_path, args.batch_real, args.subset, args=args)\n",
        "\n",
        "    # print('\\n================== Exp %d ==================\\n '%exp)\n",
        "    print('Hyper-parameters: \\n', args.__dict__)\n",
        "\n",
        "    save_dir = os.path.join(args.buffer_path, args.dataset)\n",
        "    if args.dataset == \"ImageNet\":\n",
        "        save_dir = os.path.join(save_dir, args.subset, str(args.res))\n",
        "    if args.dataset in [\"CIFAR10\", \"CIFAR100\"] and not args.zca:\n",
        "        save_dir += \"_NO_ZCA\"\n",
        "    save_dir = os.path.join(save_dir, args.model)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "    ''' organize the real dataset '''\n",
        "    images_all = []\n",
        "    labels_all = []\n",
        "    indices_class = [[] for c in range(num_classes)]\n",
        "    print(\"BUILDING DATASET\")\n",
        "    for i in tqdm(range(len(dst_train))):\n",
        "        sample = dst_train[i]\n",
        "        images_all.append(torch.unsqueeze(sample[0], dim=0))\n",
        "        labels_all.append(class_map[torch.tensor(sample[1]).item()])\n",
        "    #print('num of training images',len(images_all))\n",
        "    len_dst_train = len(images_all)  ##50000\n",
        "\n",
        "    for i, lab in tqdm(enumerate(labels_all)):\n",
        "        indices_class[lab].append(i)\n",
        "    images_all = torch.cat(images_all, dim=0).to(\"cpu\")\n",
        "    labels_all = torch.tensor(labels_all, dtype=torch.long, device=\"cpu\")\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
        "\n",
        "    for ch in range(channel):\n",
        "        print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(args.device)\n",
        "\n",
        "    trajectories = []\n",
        "\n",
        "    dst_train = TensorDataset(copy.deepcopy(images_all.detach()), copy.deepcopy(labels_all.detach()))\n",
        "    trainloader = torch.utils.data.DataLoader(dst_train, batch_size=args.batch_train, shuffle=True, num_workers=0)\n",
        "\n",
        "    ''' set augmentation for whole-dataset training '''\n",
        "    args.dc_aug_param = get_daparam(args.dataset, args.model, args.model, None)\n",
        "    args.dc_aug_param['strategy'] = 'crop_scale_rotate'  # for whole-dataset training\n",
        "    print('DC augmentation parameters: \\n', args.dc_aug_param)\n",
        "\n",
        "    for it in range(0, args.num_experts):\n",
        "\n",
        "        ''' Train synthetic data '''\n",
        "        teacher_net = get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
        "        teacher_net.train()\n",
        "        lr = args.lr_teacher\n",
        "\n",
        "\n",
        "        ##modification: using FTD here\n",
        "        from gsam import GSAM, LinearScheduler, CosineScheduler, ProportionScheduler\n",
        "        base_optimizer = torch.optim.SGD(teacher_net.parameters(), lr=lr, momentum=args.mom, weight_decay=args.l2)\n",
        "        # scheduler = CosineScheduler(T_max=args.train_epochs*len_dst_train, max_value=lr, min_value=0.0,\n",
        "            # optimizer=base_optimizer)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(base_optimizer,step_size=args.train_epochs*len(trainloader),gamma=1)\n",
        "        rho_scheduler = ProportionScheduler(pytorch_lr_scheduler=scheduler, max_lr=lr, min_lr=lr,\n",
        "            max_value=args.rho_max, min_value=args.rho_min)\n",
        "        teacher_optim = GSAM(params=teacher_net.parameters(), base_optimizer=base_optimizer,\n",
        "                model=teacher_net, gsam_alpha=args.alpha, rho_scheduler=rho_scheduler, adaptive=args.adaptive)\n",
        "\n",
        "\n",
        "        teacher_optim.zero_grad()\n",
        "\n",
        "        timestamps = []\n",
        "\n",
        "        timestamps.append([p.detach().cpu() for p in teacher_net.parameters()])\n",
        "\n",
        "        lr_schedule = [args.train_epochs // 2 + 1]\n",
        "        for e in range(args.train_epochs):\n",
        "\n",
        "            train_loss, train_acc = epoch(\"train\", dataloader=trainloader, net=teacher_net, optimizer=teacher_optim,\n",
        "                                        criterion=criterion, args=args, aug=True,scheduler=scheduler)\n",
        "\n",
        "            test_loss, test_acc = epoch(\"test\", dataloader=testloader, net=teacher_net, optimizer=None,\n",
        "                                        criterion=criterion, args=args, aug=False, scheduler=scheduler)\n",
        "\n",
        "            print(\"Itr: {}\\tEpoch: {}\\tTrain Acc: {}\\tTest Acc: {}\".format(it, e, train_acc, test_acc))\n",
        "\n",
        "            timestamps.append([p.detach().cpu() for p in teacher_net.parameters()])\n",
        "\n",
        "\n",
        "        trajectories.append(timestamps)\n",
        "\n",
        "        if len(trajectories) == args.save_interval:\n",
        "            n = 0\n",
        "            while os.path.exists(os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n))):\n",
        "                n += 1\n",
        "            print(\"Saving {}\".format(os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n))))\n",
        "            torch.save(trajectories, os.path.join(save_dir, \"replay_buffer_{}.pt\".format(n)))\n",
        "            trajectories = []\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Parameter Processing')\n",
        "    parser.add_argument('--dataset', type=str, default='CIFAR10', help='dataset')\n",
        "    parser.add_argument('--subset', type=str, default='imagenette', help='subset')\n",
        "    parser.add_argument('--model', type=str, default='ConvNet', help='model')\n",
        "    parser.add_argument('--num_experts', type=int, default=100, help='training iterations')\n",
        "    parser.add_argument('--lr_teacher', type=float, default=0.01, help='learning rate for updating network parameters')\n",
        "    parser.add_argument('--batch_train', type=int, default=256, help='batch size for training networks')\n",
        "    parser.add_argument('--batch_real', type=int, default=256, help='batch size for real loader')\n",
        "    parser.add_argument('--dsa', type=str, default='True', choices=['True', 'False'],\n",
        "                        help='whether to use differentiable Siamese augmentation.')\n",
        "    parser.add_argument('--dsa_strategy', type=str, default='color_crop_cutout_flip_scale_rotate',\n",
        "                        help='differentiable Siamese augmentation strategy')\n",
        "    parser.add_argument('--data_path', type=str, default='data', help='dataset path')\n",
        "    parser.add_argument('--buffer_path', type=str, default='./buffers', help='buffer path')\n",
        "    parser.add_argument('--train_epochs', type=int, default=50)\n",
        "    parser.add_argument('--zca', action='store_true')\n",
        "    parser.add_argument('--decay', action='store_true')\n",
        "    parser.add_argument('--mom', type=float, default=0, help='momentum')\n",
        "    parser.add_argument('--l2', type=float, default=0, help='l2 regularization')\n",
        "    parser.add_argument('--save_interval', type=int, default=10)\n",
        "    #parser.add_argument('--rho', type=float, default=0.05)\n",
        "    parser.add_argument(\"--rho_max\", default=2.0, type=float, help=\"Rho parameter for SAM.\")\n",
        "    parser.add_argument(\"--rho_min\", default=2.0, type=float, help=\"Rho parameter for SAM.\")\n",
        "    parser.add_argument(\"--alpha\", default=0.4, type=float, help=\"Rho parameter for SAM.\")\n",
        "    parser.add_argument(\"--adaptive\", default=True, type=bool, help=\"True if you want to use the Adaptive SAM.\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    main(args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils\n",
        "from tqdm import tqdm\n",
        "from utils.utils_baseline import get_dataset, get_network, get_eval_pool, evaluate_synset, get_time, DiffAugment, ParamDiffAug\n",
        "import wandb\n",
        "import copy\n",
        "import random\n",
        "from reparam_module import ReparamModule\n",
        "# from kmeans_pytorch import kmeans\n",
        "from utils.cfg import CFG as cfg\n",
        "import warnings\n",
        "import yaml\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def manual_seed(seed=0):\n",
        "\trandom.seed(seed)\n",
        "\tos.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\tnp.random.seed(seed)\n",
        "\ttorch.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed(seed)\n",
        "\ttorch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def main(args):\n",
        "\n",
        "    manual_seed()\n",
        "\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(x) for x in args.device])\n",
        "\n",
        "    if args.max_experts is not None and args.max_files is not None:\n",
        "        args.total_experts = args.max_experts * args.max_files\n",
        "\n",
        "    print(\"CUDNN STATUS: {}\".format(torch.backends.cudnn.enabled))\n",
        "\n",
        "    args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    if args.skip_first_eva==False:\n",
        "        eval_it_pool = np.arange(0, args.Iteration + 1, args.eval_it).tolist()\n",
        "    else:\n",
        "        eval_it_pool = np.arange(args.eval_it, args.Iteration + 1, args.eval_it).tolist()\n",
        "    channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader, loader_train_dict, class_map, class_map_inv = get_dataset(args.dataset, args.data_path, args.batch_real, args.subset, args=args)\n",
        "    model_eval_pool = get_eval_pool(args.eval_mode, args.model, args.model)\n",
        "\n",
        "    im_res = im_size[0]\n",
        "\n",
        "    args.im_size = im_size\n",
        "\n",
        "    accs_all_exps = dict() # record performances of all experiments\n",
        "    for key in model_eval_pool:\n",
        "        accs_all_exps[key] = []\n",
        "\n",
        "    data_save = []\n",
        "\n",
        "    if args.dsa:\n",
        "        # args.epoch_eval_train = 1000\n",
        "        args.dc_aug_param = None\n",
        "\n",
        "    args.dsa_param = ParamDiffAug()\n",
        "\n",
        "    dsa_params = args.dsa_param\n",
        "    if args.zca:\n",
        "        zca_trans = args.zca_trans\n",
        "    else:\n",
        "        zca_trans = None\n",
        "\n",
        "    wandb.init(sync_tensorboard=False,\n",
        "               project=args.project,\n",
        "               job_type=\"CleanRepo\",\n",
        "               config=args,\n",
        "               )\n",
        "\n",
        "    args = type('', (), {})()\n",
        "\n",
        "    for key in wandb.config._items:\n",
        "        setattr(args, key, wandb.config._items[key])\n",
        "\n",
        "    args.dsa_param = dsa_params\n",
        "    args.zca_trans = zca_trans\n",
        "\n",
        "    if args.batch_syn is None:\n",
        "        args.batch_syn = num_classes * args.ipc\n",
        "\n",
        "    args.distributed = torch.cuda.device_count() > 1\n",
        "\n",
        "\n",
        "    print('Hyper-parameters: \\n', args.__dict__)\n",
        "    print('Evaluation model pool: ', model_eval_pool)\n",
        "\n",
        "    ''' organize the real dataset '''\n",
        "    images_all = []\n",
        "    labels_all = []\n",
        "    indices_class = [[] for c in range(num_classes)]\n",
        "    print(\"BUILDING DATASET\")\n",
        "    if args.dataset == 'ImageNet1K' and os.path.exists('images_all.pt') and os.path.exists('labels_all.pt'):\n",
        "        images_all = torch.load('images_all.pt')\n",
        "        labels_all = torch.load('labels_all.pt')\n",
        "    else:\n",
        "        for i in tqdm(range(len(dst_train))):\n",
        "            sample = dst_train[i]\n",
        "            images_all.append(torch.unsqueeze(sample[0], dim=0))\n",
        "            labels_all.append(class_map[torch.tensor(sample[1]).item()])\n",
        "        images_all = torch.cat(images_all, dim=0).to(\"cpu\")\n",
        "        labels_all = torch.tensor(labels_all, dtype=torch.long, device=\"cpu\")\n",
        "        if args.dataset == 'ImageNet1K':\n",
        "            torch.save(images_all, 'images_all.pt')\n",
        "            torch.save(labels_all, 'labels_all.pt')\n",
        "\n",
        "    for i, lab in tqdm(enumerate(labels_all)):\n",
        "        indices_class[lab].append(i)\n",
        "\n",
        "\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        print('class c = %d: %d real images'%(c, len(indices_class[c])))\n",
        "\n",
        "    for ch in range(channel):\n",
        "        print('real images channel %d, mean = %.4f, std = %.4f'%(ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch])))\n",
        "\n",
        "\n",
        "    def get_images(c, n):  # get random n images from class c\n",
        "        idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
        "        return images_all[idx_shuffle]\n",
        "\n",
        "\n",
        "    ''' initialize the synthetic data '''\n",
        "    label_syn = torch.tensor([np.ones(args.ipc)*i for i in range(num_classes)], dtype=torch.long, requires_grad=False, device=args.device).view(-1) # [0,0,0, 1,1,1, ..., 9,9,9]\n",
        "\n",
        "\n",
        "    image_syn = torch.randn(size=(num_classes * args.ipc, channel, im_size[0], im_size[1]), dtype=torch.float)\n",
        "\n",
        "    syn_lr = torch.tensor(args.lr_teacher).to(args.device)\n",
        "    expert_dir = os.path.join(args.buffer_path, args.dataset)\n",
        "    if args.dataset == \"ImageNet\":\n",
        "        expert_dir = os.path.join(expert_dir, args.subset, str(args.res))\n",
        "    if args.dataset in [\"CIFAR10\", \"CIFAR100\"] and not args.zca:\n",
        "        expert_dir += \"_NO_ZCA\"\n",
        "    expert_dir = os.path.join(expert_dir, args.model)\n",
        "    print(\"Expert Dir: {}\".format(expert_dir))\n",
        "    if args.load_all:\n",
        "        buffer = []\n",
        "        n = 0\n",
        "        while os.path.exists(os.path.join(expert_dir, \"replay_buffer_{}.pt\".format(n))):\n",
        "            buffer = buffer + torch.load(os.path.join(expert_dir, \"replay_buffer_{}.pt\".format(n)))\n",
        "            n += 1\n",
        "        if n == 0:\n",
        "            raise AssertionError(\"No buffers detected at {}\".format(expert_dir))\n",
        "\n",
        "    else:\n",
        "        expert_files = []\n",
        "        n = 0\n",
        "        while os.path.exists(os.path.join(expert_dir, \"replay_buffer_{}.pt\".format(n))):\n",
        "            expert_files.append(os.path.join(expert_dir, \"replay_buffer_{}.pt\".format(n)))\n",
        "            n += 1\n",
        "        if n == 0:\n",
        "            raise AssertionError(\"No buffers detected at {}\".format(expert_dir))\n",
        "        file_idx = 0\n",
        "        expert_idx = 0\n",
        "        # random.shuffle(expert_files)\n",
        "        if args.max_files is not None:\n",
        "            expert_files = expert_files[:args.max_files]\n",
        "\n",
        "        expert_id = [i for i in range(len(expert_files))]\n",
        "        random.shuffle(expert_id)\n",
        "\n",
        "        print(\"loading file {}\".format(expert_files[expert_id[file_idx]]))\n",
        "        buffer = torch.load(expert_files[expert_id[file_idx]])\n",
        "        if args.max_experts is not None:\n",
        "            buffer = buffer[:args.max_experts]\n",
        "        buffer_id = [i for i in range(len(buffer))]\n",
        "        random.shuffle(buffer_id)\n",
        "\n",
        "    if args.pix_init == 'real':\n",
        "        print('initialize synthetic data from random real images')\n",
        "        for c in range(num_classes):\n",
        "            image_syn.data[c * args.ipc:(c + 1) * args.ipc] = get_images(c, args.ipc).detach().data\n",
        "\n",
        "\n",
        "    elif args.pix_init == 'samples_predicted_correctly':\n",
        "        if args.parall_eva==False:\n",
        "            device = torch.device(\"cuda:0\")\n",
        "        else:\n",
        "            device = args.device\n",
        "        if cfg.Initialize_Label_With_Another_Model:\n",
        "            Temp_net = get_network(args.Initialize_Label_Model, channel, num_classes, im_size, dist=False).to(device)  # get a random model\n",
        "        else:\n",
        "            Temp_net = get_network(args.model, channel, num_classes, im_size, dist=False).to(device)  # get a random model\n",
        "        Temp_net.eval()\n",
        "        Temp_net = ReparamModule(Temp_net)\n",
        "        if args.distributed and args.parall_eva==True:\n",
        "            Temp_net = torch.nn.DataParallel(Temp_net)\n",
        "        Temp_net.eval()\n",
        "        logits=[]\n",
        "        label_expert_files = expert_files\n",
        "        temp_params = torch.load(label_expert_files[0])[0][args.Label_Model_Timestamp]\n",
        "        temp_params = torch.cat([p.data.to(device).reshape(-1) for p in temp_params], 0)\n",
        "        if args.distributed and args.parall_eva==True:\n",
        "            temp_params = temp_params.unsqueeze(0).expand(torch.cuda.device_count(), -1)\n",
        "        for c in range(num_classes):\n",
        "            data_for_class_c = get_images(c, len(indices_class[c])).detach().data\n",
        "            n, _, w, h = data_for_class_c.shape\n",
        "            selected_num = 0\n",
        "            select_times = 0\n",
        "            cur=0\n",
        "            temp_img = None\n",
        "            Wrong_Predicted_Img = None\n",
        "            batch_size = 256\n",
        "            index = []\n",
        "            while len(index)<args.ipc:\n",
        "                print(str(c)+'.'+str(select_times)+'.'+str(cur))\n",
        "                current_data_batch = data_for_class_c[batch_size*select_times : batch_size*(select_times+1)].detach().to(device)\n",
        "                if batch_size*select_times > len(data_for_class_c):\n",
        "                    select_times = 0\n",
        "                    cur+=1\n",
        "                    temp_params = torch.load(label_expert_files[int(cur/10)%10])[cur%10][args.Label_Model_Timestamp]\n",
        "                    temp_params = torch.cat([p.data.to(device).reshape(-1) for p in temp_params], 0).to(device)\n",
        "                    if args.distributed and args.parall_eva==True:\n",
        "                        temp_params = temp_params.unsqueeze(0).expand(torch.cuda.device_count(), -1)\n",
        "                    continue\n",
        "                logits = Temp_net(current_data_batch, flat_param=temp_params).detach()\n",
        "                prediction_class = np.argmax(logits.cpu().data.numpy(), axis=-1)\n",
        "                for i in range(len(prediction_class)):\n",
        "                    if prediction_class[i]==c and len(index)<args.ipc:\n",
        "                        index.append(batch_size*select_times+i)\n",
        "                        index=list(set(index))\n",
        "                select_times+=1\n",
        "                if len(index) == args.ipc:\n",
        "                    temp_img = torch.index_select(data_for_class_c, dim=0, index=torch.tensor(index))\n",
        "                    break\n",
        "            image_syn.data[c * args.ipc:(c + 1) * args.ipc] = temp_img.detach()\n",
        "    else:\n",
        "        print('initialize synthetic data from random noise')\n",
        "\n",
        "\n",
        "    ''' training '''\n",
        "    image_syn = image_syn.detach().to(args.device).requires_grad_(True)\n",
        "    syn_lr = syn_lr.detach().to(args.device).requires_grad_(True)\n",
        "\n",
        "    optimizer_img = torch.optim.SGD([image_syn], lr=args.lr_img, momentum=0.5)\n",
        "    optimizer_lr = torch.optim.SGD([syn_lr], lr=args.lr_lr, momentum=0.5)\n",
        "\n",
        "\n",
        "\n",
        "    optimizer_img.zero_grad()\n",
        "\n",
        "    ###\n",
        "\n",
        "    '''test'''\n",
        "    def SoftCrossEntropy(inputs, target, reduction='average'):\n",
        "        input_log_likelihood = -F.log_softmax(inputs, dim=1)\n",
        "        target_log_likelihood = F.softmax(target, dim=1)\n",
        "        batch = inputs.shape[0]\n",
        "        loss = torch.sum(torch.mul(input_log_likelihood, target_log_likelihood)) / batch\n",
        "        return loss\n",
        "\n",
        "    criterion = SoftCrossEntropy\n",
        "\n",
        "    print('%s training begins'%get_time())\n",
        "    best_acc = {m: 0 for m in model_eval_pool}\n",
        "    best_std = {m: 0 for m in model_eval_pool}\n",
        "\n",
        "    '''------test------'''\n",
        "    '''only sum correct predicted logits'''\n",
        "    if args.pix_init == \"samples_predicted_correctly\":\n",
        "        if cfg.Initialize_Label_With_Another_Model:\n",
        "            Temp_net = get_network(args.Initialize_Label_Model, channel, num_classes, im_size, dist=False).to(device)  # get a random model\n",
        "        else:\n",
        "            Temp_net = get_network(args.model, channel, num_classes, im_size, dist=False).to(device)  # get a random model\n",
        "        Temp_net.eval()\n",
        "        Temp_net = ReparamModule(Temp_net)\n",
        "        if args.distributed:\n",
        "            Temp_net = torch.nn.DataParallel(Temp_net)\n",
        "        Temp_net.eval()\n",
        "        logits=[]\n",
        "        batch_size = 256\n",
        "        for i in range(len(label_expert_files)):\n",
        "            Temp_Buffer = torch.load(label_expert_files[i])\n",
        "            for j in Temp_Buffer:\n",
        "                temp_logits = None\n",
        "                for select_times in range((len(image_syn)+batch_size-1)//batch_size):\n",
        "                    current_data_batch = image_syn[batch_size*select_times : batch_size*(select_times+1)].detach().to(device)\n",
        "                    Temp_params = j[args.Label_Model_Timestamp]\n",
        "                    Initialize_Labels_params = torch.cat([p.data.to(args.device).reshape(-1) for p in Temp_params], 0)\n",
        "                    if args.distributed:\n",
        "                        Initialize_Labels_params = Initialize_Labels_params.unsqueeze(0).expand(torch.cuda.device_count(), -1)\n",
        "                    Initialized_Labels = Temp_net(current_data_batch, flat_param=Initialize_Labels_params)\n",
        "                    if temp_logits == None:\n",
        "                        temp_logits = Initialized_Labels.detach()\n",
        "                    else:\n",
        "                        temp_logits = torch.cat((temp_logits, Initialized_Labels.detach()),0)\n",
        "                logits.append(temp_logits.detach().cpu())\n",
        "        logits_tensor = torch.stack(logits)\n",
        "        true_labels = label_syn.cpu()\n",
        "        predicted_labels = torch.argmax(logits_tensor, dim=2).cpu()\n",
        "        correct_predictions = predicted_labels == true_labels.view(1, -1)\n",
        "        mask = correct_predictions.unsqueeze(2)\n",
        "        correct_logits = logits_tensor * mask.float()\n",
        "        correct_logits_per_model = correct_logits.sum(dim=0)\n",
        "        num_correct_images_per_model = correct_predictions.sum(dim=0, dtype=torch.float)\n",
        "        average_logits_per_image = correct_logits_per_model / num_correct_images_per_model.unsqueeze(1)\n",
        "        Initialized_Labels = average_logits_per_image\n",
        "\n",
        "    elif args.pix_init == \"real\":\n",
        "        Temp_net = get_network(args.model, channel, num_classes, im_size, dist=False).to(args.device)  # get a random model\n",
        "        Temp_net = ReparamModule(Temp_net)\n",
        "        if args.distributed:\n",
        "            Temp_net = torch.nn.DataParallel(Temp_net)\n",
        "        Temp_net.eval()\n",
        "        Temp_params = buffer[0][-1]\n",
        "        Initialize_Labels_params = torch.cat([p.data.to(args.device).reshape(-1) for p in Temp_params], 0)\n",
        "        if args.distributed:\n",
        "            Initialize_Labels_params = Initialize_Labels_params.unsqueeze(0).expand(torch.cuda.device_count(), -1)\n",
        "        Initialized_Labels = Temp_net(image_syn, flat_param=Initialize_Labels_params)\n",
        "\n",
        "    acc = np.sum(np.equal(np.argmax(Initialized_Labels.cpu().data.numpy(), axis=-1), label_syn.cpu().data.numpy()))\n",
        "    print('InitialAcc:{}'.format(acc/len(label_syn)))\n",
        "\n",
        "    label_syn = copy.deepcopy(Initialized_Labels.detach()).to(args.device).requires_grad_(True)\n",
        "    label_syn.requires_grad=True\n",
        "    label_syn = label_syn.to(args.device)\n",
        "\n",
        "\n",
        "    optimizer_y = torch.optim.SGD([label_syn], lr=args.lr_y, momentum=args.Momentum_y)\n",
        "    vs = torch.zeros_like(label_syn)\n",
        "    accumulated_grad = torch.zeros_like(label_syn)\n",
        "    last_random = 0\n",
        "\n",
        "    del Temp_net\n",
        "\n",
        "    # test\n",
        "    curMax_times = 0\n",
        "    current_accumulated_step = 0\n",
        "\n",
        "    for it in range(0, args.Iteration+1):\n",
        "        save_this_it = False\n",
        "        wandb.log({\"Progress\": it}, step=it)\n",
        "        ''' Evaluate synthetic data '''\n",
        "        if it in eval_it_pool:\n",
        "            for model_eval in model_eval_pool:\n",
        "                print('-------------------------\\nEvaluation\\nmodel_train = %s, model_eval = %s, iteration = %d'%(args.model, model_eval, it))\n",
        "                if args.dsa:\n",
        "                    print('DSA augmentation strategy: \\n', args.dsa_strategy)\n",
        "                    print('DSA augmentation parameters: \\n', args.dsa_param.__dict__)\n",
        "                else:\n",
        "                    print('DC augmentation parameters: \\n', args.dc_aug_param)\n",
        "\n",
        "                accs_test = []\n",
        "                accs_train = []\n",
        "\n",
        "                for it_eval in range(args.num_eval):\n",
        "                    if args.parall_eva==False:\n",
        "                        device = torch.device(\"cuda:0\")\n",
        "                        net_eval = get_network(model_eval, channel, num_classes, im_size, dist=False).to(device) # get a random model\n",
        "                    else:\n",
        "                        device = args.device\n",
        "                        net_eval = get_network(model_eval, channel, num_classes, im_size, dist=True).to(device) # get a random model\n",
        "\n",
        "                    eval_labs = label_syn.detach().to(device)\n",
        "                    with torch.no_grad():\n",
        "                        image_save = image_syn.to(device)\n",
        "                    image_syn_eval, label_syn_eval = copy.deepcopy(image_save.detach()).to(device), copy.deepcopy(eval_labs.detach()).to(device) # avoid any unaware modification\n",
        "\n",
        "                    args.lr_net = syn_lr.item()\n",
        "                    _, acc_train, acc_test = evaluate_synset(it_eval, copy.deepcopy(net_eval).to(device), image_syn_eval.to(device), label_syn_eval.to(device), testloader, args, texture=False, train_criterion=criterion)\n",
        "                    accs_test.append(acc_test)\n",
        "                    accs_train.append(acc_train)\n",
        "\n",
        "                accs_test = np.array(accs_test)\n",
        "                accs_train = np.array(accs_train)\n",
        "                acc_test_mean = np.mean(accs_test)\n",
        "                acc_test_std = np.std(accs_test)\n",
        "\n",
        "                if acc_test_mean > best_acc[model_eval]:\n",
        "                    best_acc[model_eval] = acc_test_mean\n",
        "                    best_std[model_eval] = acc_test_std\n",
        "                    save_this_it = True\n",
        "                print('Evaluate %d random %s, mean = %.4f std = %.4f\\n-------------------------'%(len(accs_test), model_eval, acc_test_mean, acc_test_std))\n",
        "                wandb.log({'Accuracy/{}'.format(model_eval): acc_test_mean}, step=it)\n",
        "                wandb.log({'Max_Accuracy/{}'.format(model_eval): best_acc[model_eval]}, step=it)\n",
        "                wandb.log({'Std/{}'.format(model_eval): acc_test_std}, step=it)\n",
        "                wandb.log({'Max_Std/{}'.format(model_eval): best_std[model_eval]}, step=it)\n",
        "\n",
        "        if it in eval_it_pool and (save_this_it or it % 1000 == 0):\n",
        "            with torch.no_grad():\n",
        "                image_save = image_syn.cuda()\n",
        "                save_dir = os.path.join(\".\", \"logged_files\", args.dataset, str(args.ipc), args.model, wandb.run.name)\n",
        "\n",
        "                if not os.path.exists(save_dir):\n",
        "                    os.makedirs(os.path.join(save_dir,'Normal'))\n",
        "\n",
        "                torch.save(image_save.cpu(), os.path.join(save_dir, 'Normal',\"images_{}.pt\".format(it)))\n",
        "                torch.save(label_syn.cpu(), os.path.join(save_dir, 'Normal', \"labels_{}.pt\".format(it)))\n",
        "                torch.save(syn_lr.detach().cpu(), os.path.join(save_dir, 'Normal', \"lr_{}.pt\".format(it)))\n",
        "\n",
        "                if save_this_it:\n",
        "                    torch.save(image_save.cpu(), os.path.join(save_dir, 'Normal', \"images_best.pt\".format(it)))\n",
        "                    torch.save(label_syn.cpu(), os.path.join(save_dir, 'Normal', \"labels_best.pt\".format(it)))\n",
        "                    torch.save(syn_lr.detach().cpu(), os.path.join(save_dir, 'Normal', \"lr_best.pt\".format(it)))\n",
        "\n",
        "                wandb.log({\"Pixels\": wandb.Histogram(torch.nan_to_num(image_syn.detach().cpu()))}, step=it)\n",
        "\n",
        "                if args.ipc < 50 or args.force_save:\n",
        "                    upsampled = image_save\n",
        "                    if args.dataset != \"ImageNet\":\n",
        "                        upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=2)\n",
        "                        upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=3)\n",
        "                    grid = torchvision.utils.make_grid(upsampled, nrow=10, normalize=True, scale_each=True)\n",
        "                    wandb.log({\"Synthetic_Images\": wandb.Image(torch.nan_to_num(grid.detach().cpu()))}, step=it)\n",
        "                    wandb.log({'Synthetic_Pixels': wandb.Histogram(torch.nan_to_num(image_save.detach().cpu()))}, step=it)\n",
        "\n",
        "                    for clip_val in [2.5]:\n",
        "                        std = torch.std(image_save)\n",
        "                        mean = torch.mean(image_save)\n",
        "                        upsampled = torch.clip(image_save, min=mean-clip_val*std, max=mean+clip_val*std)\n",
        "                        if args.dataset != \"ImageNet\":\n",
        "                            upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=2)\n",
        "                            upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=3)\n",
        "                        grid = torchvision.utils.make_grid(upsampled, nrow=10, normalize=True, scale_each=True)\n",
        "                        wandb.log({\"Clipped_Synthetic_Images/std_{}\".format(clip_val): wandb.Image(torch.nan_to_num(grid.detach().cpu()))}, step=it)\n",
        "\n",
        "                    if args.zca:\n",
        "                        image_save = image_save.to(args.device)\n",
        "                        image_save = args.zca_trans.inverse_transform(image_save)\n",
        "                        image_save.cpu()\n",
        "                        torch.save(image_save.cpu(), os.path.join(save_dir, 'Normal', \"images_zca_{}.pt\".format(it)))\n",
        "                        upsampled = image_save\n",
        "                        if args.dataset != \"ImageNet\":\n",
        "                            upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=2)\n",
        "                            upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=3)\n",
        "                        grid = torchvision.utils.make_grid(upsampled, nrow=10, normalize=True, scale_each=True)\n",
        "                        wandb.log({\"Reconstructed_Images\": wandb.Image(torch.nan_to_num(grid.detach().cpu()))}, step=it)\n",
        "                        wandb.log({'Reconstructed_Pixels': wandb.Histogram(torch.nan_to_num(image_save.detach().cpu()))}, step=it)\n",
        "                        for clip_val in [2.5]:\n",
        "                            std = torch.std(image_save)\n",
        "                            mean = torch.mean(image_save)\n",
        "                            upsampled = torch.clip(image_save, min=mean - clip_val * std, max=mean + clip_val * std)\n",
        "                            if args.dataset != \"ImageNet\":\n",
        "                                upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=2)\n",
        "                                upsampled = torch.repeat_interleave(upsampled, repeats=4, dim=3)\n",
        "                            grid = torchvision.utils.make_grid(upsampled, nrow=10, normalize=True, scale_each=True)\n",
        "                            wandb.log({\"Clipped_Reconstructed_Images/std_{}\".format(clip_val): wandb.Image(\n",
        "                                torch.nan_to_num(grid.detach().cpu()))}, step=it)\n",
        "\n",
        "\n",
        "\n",
        "        wandb.log({\"Synthetic_LR\": syn_lr.detach().cpu()}, step=it)\n",
        "\n",
        "        student_net = get_network(args.model, channel, num_classes, im_size, dist=False).to(args.device)  # get a random model\n",
        "\n",
        "        student_net = ReparamModule(student_net)\n",
        "\n",
        "        if args.distributed:\n",
        "            student_net = torch.nn.DataParallel(student_net)\n",
        "\n",
        "        student_net.train()\n",
        "\n",
        "        num_params = sum([np.prod(p.size()) for p in (student_net.parameters())])\n",
        "\n",
        "        if args.load_all:\n",
        "            expert_trajectory = buffer[np.random.randint(0, len(buffer))]\n",
        "        else:\n",
        "            expert_trajectory = buffer[buffer_id[expert_idx]]\n",
        "            expert_idx += 1\n",
        "            if expert_idx == len(buffer):\n",
        "                expert_idx = 0\n",
        "                file_idx += 1\n",
        "                if file_idx == len(expert_files):\n",
        "                    file_idx = 0\n",
        "                    random.shuffle(expert_id)\n",
        "                print(\"loading file {}\".format(expert_files[expert_id[file_idx]]))\n",
        "                if args.max_files != 1:\n",
        "                    del buffer\n",
        "                    buffer = torch.load(expert_files[expert_id[file_idx]])\n",
        "                if args.max_experts is not None:\n",
        "                    buffer = buffer[:args.max_experts]\n",
        "                random.shuffle(buffer_id)\n",
        "\n",
        "        # Only match easy traj. in the early stage\n",
        "        if args.Sequential_Generation:\n",
        "            Upper_Bound = args.current_max_start_epoch + int((args.max_start_epoch-args.current_max_start_epoch) * it/(args.expansion_end_epoch))\n",
        "            Upper_Bound = min(Upper_Bound, args.max_start_epoch)\n",
        "        else:\n",
        "            Upper_Bound = args.max_start_epoch\n",
        "\n",
        "        start_epoch = np.random.randint(args.min_start_epoch, Upper_Bound)\n",
        "\n",
        "        starting_params = expert_trajectory[start_epoch]\n",
        "        target_params = expert_trajectory[start_epoch+args.expert_epochs]\n",
        "        target_params = torch.cat([p.data.to(args.device).reshape(-1) for p in target_params], 0)\n",
        "        student_params = [torch.cat([p.data.to(args.device).reshape(-1) for p in starting_params], 0).requires_grad_(True)]\n",
        "        starting_params = torch.cat([p.data.to(args.device).reshape(-1) for p in starting_params], 0)\n",
        "\n",
        "        syn_images = image_syn\n",
        "        y_hat = label_syn\n",
        "\n",
        "        param_loss_list = []\n",
        "        param_dist_list = []\n",
        "        indices_chunks = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for step in range(args.syn_steps):\n",
        "            if not indices_chunks:\n",
        "                indices = torch.randperm(len(syn_images))\n",
        "                indices_chunks = list(torch.split(indices, args.batch_syn))\n",
        "\n",
        "            these_indices = indices_chunks.pop()\n",
        "\n",
        "            x = syn_images[these_indices]\n",
        "            this_y = y_hat[these_indices]\n",
        "\n",
        "\n",
        "            if args.dsa and (not args.no_aug):\n",
        "                x = DiffAugment(x, args.dsa_strategy, param=args.dsa_param)\n",
        "\n",
        "            if args.distributed:\n",
        "                forward_params = student_params[-1].unsqueeze(0).expand(torch.cuda.device_count(), -1)\n",
        "            else:\n",
        "                forward_params = student_params[-1]\n",
        "            x = student_net(x, flat_param=forward_params)\n",
        "            ce_loss = criterion(x, this_y)\n",
        "\n",
        "            grad = torch.autograd.grad(ce_loss, student_params[-1], create_graph=True)[0]\n",
        "\n",
        "            student_params.append(student_params[-1] - syn_lr * grad)\n",
        "\n",
        "        param_loss = torch.tensor(0.0).to(args.device)\n",
        "        param_dist = torch.tensor(0.0).to(args.device)\n",
        "\n",
        "        param_loss += torch.nn.functional.mse_loss(student_params[-1], target_params, reduction=\"sum\")\n",
        "        param_dist += torch.nn.functional.mse_loss(starting_params, target_params, reduction=\"sum\")\n",
        "\n",
        "        param_loss_list.append(param_loss)\n",
        "        param_dist_list.append(param_dist)\n",
        "\n",
        "        param_loss /= num_params\n",
        "        param_dist /= num_params\n",
        "\n",
        "        param_loss /= param_dist\n",
        "\n",
        "        grand_loss = param_loss\n",
        "\n",
        "        optimizer_img.zero_grad()\n",
        "        optimizer_lr.zero_grad()\n",
        "        optimizer_y.zero_grad()\n",
        "\n",
        "        grand_loss.backward()\n",
        "\n",
        "        if grand_loss<=args.threshold:\n",
        "            optimizer_y.step()\n",
        "            optimizer_img.step()\n",
        "            optimizer_lr.step()\n",
        "        else:\n",
        "            wandb.log({\"falts\": start_epoch}, step=it)\n",
        "\n",
        "\n",
        "\n",
        "        wandb.log({\"Grand_Loss\": param_loss.detach().cpu(),\n",
        "                   \"Start_Epoch\": start_epoch})\n",
        "\n",
        "        for _ in student_params:\n",
        "            del _\n",
        "\n",
        "        if it%10 == 0:\n",
        "            print('%s iter = %04d, loss = %.4f' % (get_time(), it, grand_loss.item()))\n",
        "\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Parameter Processing')\n",
        "\n",
        "    parser.add_argument(\"--cfg\", type=str, default=\"\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    cfg.merge_from_file(args.cfg)\n",
        "    for key, value in cfg.items():\n",
        "        arg_name = '--' + key\n",
        "        parser.add_argument(arg_name, type=type(value), default=value)\n",
        "    args = parser.parse_args()\n",
        "    main(args)"
      ],
      "metadata": {
        "id": "vwMErpK7nGx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicUnit(nn.Module):\n",
        "    def __init__(self, channels: int, dropout: float):\n",
        "        super(BasicUnit, self).__init__()\n",
        "        self.block = nn.Sequential(OrderedDict([\n",
        "            (\"0_normalization\", nn.BatchNorm2d(channels)),\n",
        "            (\"1_activation\", nn.ReLU(inplace=True)),\n",
        "            (\"2_convolution\", nn.Conv2d(channels, channels, (3, 3), stride=1, padding=1, bias=False)),\n",
        "            (\"3_normalization\", nn.BatchNorm2d(channels)),\n",
        "            (\"4_activation\", nn.ReLU(inplace=True)),\n",
        "            (\"5_dropout\", nn.Dropout(dropout, inplace=True)),\n",
        "            (\"6_convolution\", nn.Conv2d(channels, channels, (3, 3), stride=1, padding=1, bias=False)),\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "class DownsampleUnit(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int, dropout: float):\n",
        "        super(DownsampleUnit, self).__init__()\n",
        "        self.norm_act = nn.Sequential(OrderedDict([\n",
        "            (\"0_normalization\", nn.BatchNorm2d(in_channels)),\n",
        "            (\"1_activation\", nn.ReLU(inplace=True)),\n",
        "        ]))\n",
        "        self.block = nn.Sequential(OrderedDict([\n",
        "            (\"0_convolution\", nn.Conv2d(in_channels, out_channels, (3, 3), stride=stride, padding=1, bias=False)),\n",
        "            (\"1_normalization\", nn.BatchNorm2d(out_channels)),\n",
        "            (\"2_activation\", nn.ReLU(inplace=True)),\n",
        "            (\"3_dropout\", nn.Dropout(dropout, inplace=True)),\n",
        "            (\"4_convolution\", nn.Conv2d(out_channels, out_channels, (3, 3), stride=1, padding=1, bias=False)),\n",
        "        ]))\n",
        "        self.downsample = nn.Conv2d(in_channels, out_channels, (1, 1), stride=stride, padding=0, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm_act(x)\n",
        "        return self.block(x) + self.downsample(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, stride: int, depth: int, dropout: float):\n",
        "        super(Block, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            DownsampleUnit(in_channels, out_channels, stride, dropout),\n",
        "            *(BasicUnit(out_channels, dropout) for _ in range(depth))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth: int, width_factor: int, dropout: float, in_channels: int, labels: int):\n",
        "        super(WideResNet, self).__init__()\n",
        "\n",
        "        self.filters = [16, 1 * 16 * width_factor, 2 * 16 * width_factor, 4 * 16 * width_factor]\n",
        "        self.block_depth = (depth - 4) // (3 * 2)\n",
        "\n",
        "        self.f = nn.Sequential(OrderedDict([\n",
        "            (\"0_convolution\", nn.Conv2d(in_channels, self.filters[0], (3, 3), stride=1, padding=1, bias=False)),\n",
        "            (\"1_block\", Block(self.filters[0], self.filters[1], 1, self.block_depth, dropout)),\n",
        "            (\"2_block\", Block(self.filters[1], self.filters[2], 2, self.block_depth, dropout)),\n",
        "            (\"3_block\", Block(self.filters[2], self.filters[3], 2, self.block_depth, dropout)),\n",
        "            (\"4_normalization\", nn.BatchNorm2d(self.filters[3])),\n",
        "            (\"5_activation\", nn.ReLU(inplace=True)),\n",
        "            (\"6_pooling\", nn.AvgPool2d(kernel_size=8)),\n",
        "            (\"7_flattening\", nn.Flatten()),\n",
        "            (\"8_classification\", nn.Linear(in_features=self.filters[3], out_features=labels)),\n",
        "        ]))\n",
        "\n",
        "        self._initialize()\n",
        "\n",
        "    def _initialize(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight.data, mode=\"fan_in\", nonlinearity=\"relu\")\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.zero_()\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.f(x)"
      ],
      "metadata": {
        "id": "LNB5mxUInJYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "mnist_train = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "\n",
        "teacher_network = WideResNet()\n",
        "condensed_images, condensed_labels = apply_DATM(teacher_network, mnist_train)\n",
        "\n",
        "condensed_dataset = TensorDataset(condensed_images, condensed_labels)\n",
        "train_loader = DataLoader(condensed_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "\n",
        "student_network = WideResNet()\n",
        "optimizer = optim.SGD(student_network.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(10):\n",
        "    student_network.train()\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = student_network(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "mnist_test = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(mnist_test, batch_size=1000, shuffle=False)\n",
        "correct = 0\n",
        "total = 0\n",
        "student_network.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = student_network(data)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hHCHGZrLnLuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVssTwCMnOKt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}